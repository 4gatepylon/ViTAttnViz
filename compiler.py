# NOTE these two are hard-coded because they are in the template.
START_REPLACEMENT_UUID = "4044e411-a988-4834-b453-193d4bbef321"
END_REPLACEMENT_UUID = "b180600e-4295-4f5d-8b13-bd0992b955f3"

# Fine the line with the uuids
# replace shit between with our desired lines

import click
import numpy as np
import json
import tqdm
from jaxtyping import Float
from typing import Iterable, Tuple, Union, List, Optional
from pathlib import Path


def process_file(
    input_pairs: Iterable[
        Tuple[
            Path,
            Float[np.ndarray, "n1 m1 n2 m2"],
        ]
    ],
    input_file: Path = Path("visualizer_template.html"),
    output_file: Optional[Path] = None,
    no_clobber: bool = False,
) -> Optional[str]:
    """Create a HTML file or string that can be rendered by a browser, assuming the images desired actually
    are present where claimed, that can allow hover-based attention review for ViT-style visual transformers.

    Args:
        input_pairs (Iterable[ Tuple[ Path, Tensor]): A list of pairs of path and corresponding attention
            "matrix" in a visualizeable interpretation. The first two dimensions (coordinates) tell you which
            patch you care about, and the last two tell you which is being attended to.
        input_file (Path, optional): where to read the HTML template from; You will almost never
            modify this. Defaults to Path("visualizer_template.html").
        output_file (Optional[Path], optional): the where to write to, if None, then will RETURN the output as
            a STRING (proper way to do it for IPython Jupyter Notebooks). Defaults to None.
        no_clobber (bool, optional): when you are writing to a file, you can use this flag to avoid
            dumb mistakes in which you overwrite the previous file by accident. Defaults to False.

    Returns:
        Optional[str]: potentially, the HTML string (if not written to a file).
    """
    if not input_file.exists():
        raise ValueError(f"No input file {input_file.as_posix()}")
    if no_clobber and output_file is not None and output_file.exists():
        raise ValueError(f"Cannot clobber {output_file.as_posix()}")

    # Convert torch tensors to numpy if necessary
    processed_pairs = [
        (filename.resolve().as_posix(), tensor) for filename, tensor in input_pairs
    ]

    # Read the template file
    with open(input_file, "r") as f:
        lines = [l.replace("\n", "") for l in f.readlines()]

    # print("\n".join(lines)) # DEBUG

    start_idx = None
    end_idx = None
    # Start lines
    for idx, line in enumerate(lines):
        assert END_REPLACEMENT_UUID not in line
        if START_REPLACEMENT_UUID in line:
            start_idx = idx
            print("BREAK START", start_idx, idx)  # XXX
            break
    if start_idx is None:
        raise RuntimeError(
            f"Could not find {START_REPLACEMENT_UUID} in {input_file.as_posix()} (start_idx={start_idx})"
        )
    # End lines
    for idx, line in enumerate(lines[start_idx + 1 :], start=start_idx + 1):
        assert START_REPLACEMENT_UUID not in line
        if END_REPLACEMENT_UUID in line:
            end_idx = idx
            break
    if end_idx is None:
        raise RuntimeError(
            f"Could not find {END_REPLACEMENT_UUID} in {input_file.as_posix()} (end_idx={end_idx})"
        )
    before_lines = lines[:start_idx]
    after_lines = lines[end_idx + 1 :]

    # Create the new lines to insert
    # 1. Add the current image
    new_lines = [
        "//////////////// START AUTOGENERATED CODE ////////////////",
        f'const current_image = ["{processed_pairs[0][0]}"];',  # Filename (Default will grab [0][0])
    ]
    # 2. Add the list of all images
    new_lines.append(
        # All filenames as a list in JS
        "const images = ["
        + ", ".join([f'"{pair[0]}"' for pair in processed_pairs])
        + "];"
    )
    # 3. Add all the tensors
    new_lines.append("const tensors = {")
    for path, tensor in processed_pairs:
        # NOTE this WILL include newlines but that is OK!
        new_lines.append(f'"{path}": {json.dumps(tensor.tolist())},')
    new_lines.append("};")

    # 4. Add the selection tensors
    new_lines.append("const selection_tensors = {")
    for path, tensor in processed_pairs:
        n1, m1, n2, m2 = tensor.shape
        new_lines.append(f'"{path}": createTransluscentTensor({n1}, {m1}),')
    new_lines.append("};")
    new_lines.append(
        "//////////////// END AUTOGENERATED CODE ////////////////",
    )

    # Replace the content between UUIDs
    new_content = (
        "\n".join(before_lines)
        + "\n"
        + "\n".join(new_lines)
        + "\n"
        + "\n".join(after_lines)
    )

    # Write the output file
    if output_file is not None:
        with open(output_file, "w") as f:
            f.write(new_content)
        click.echo(f"Successfully wrote to {output_file}")
        return new_content
    else:
        return new_content


@click.command()
@click.argument("input_pairs", nargs=-1, type=click.Path(exists=True))
@click.option(
    "--input-file", default="visualizer_template.html", help="Input template file"
)
@click.option("--output-file", default="visualizer.html", help="Output file")
@click.option(
    "--no-clobber", is_flag=True, help="Do not overwrite existing output file"
)
def try_random_tensors(input_pairs, input_file, output_file, no_clobber):
    """
    Demo method to try and generate a visualization for some random tensors.
    """
    # Here you would load your tensors from the input_pairs
    # For this example, I'll create dummy tensors
    processed_pairs = []
    for path in tqdm.tqdm(input_pairs):
        tensor = np.random.rand(3, 3, 4, 4)  # 3x3 in input, 4x4 in output
        processed_pairs.append((Path(path), tensor))

    process_file(processed_pairs, Path(input_file), Path(output_file), no_clobber)


if __name__ == "__main__":
    try_random_tensors()
